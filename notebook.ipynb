{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "SNAPSHOT_DATE = '2042-06-22'\n",
    "\n",
    "def non_zero_count(series):\n",
    "    return (series > 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "merchants = pd.read_excel('data/raw/merchants.xlsx')\n",
    "payments = pd.read_excel('data/raw/payments.xlsx')\n",
    "print(merchants.columns)\n",
    "print(payments.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '0.0' is the mssing value in the dataset\n",
    "merchants_processed = merchants.replace(0, np.nan)\n",
    "print(merchants_processed.shape)\n",
    "print(merchants_processed.isnull().sum())\n",
    "\n",
    "# drop the rows with nan values\n",
    "merchants_processed = merchants_processed.dropna()\n",
    "print(merchants_processed.shape)\n",
    "merchant_ids = [str(id) for id in merchants_processed['merchant'].values]\n",
    "print(len(merchant_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payments dataset, only keep the rows with merchant id in merchant_ids\n",
    "print(payments.shape)\n",
    "payments_processed = payments.copy()\n",
    "payments_processed['merchant'] = payments_processed['merchant'].astype(str)\n",
    "payments_processed = payments[payments['merchant'].isin(merchant_ids)]\n",
    "print(payments_processed.shape)\n",
    "print(payments_processed['merchant'].nunique())\n",
    "\n",
    "# payments_processed['date'] = pd.to_datetime(payments_processed['date'])\n",
    "# payment date range\n",
    "print(payments_processed['date'].min())\n",
    "print(payments_processed['date'].max())\n",
    "\n",
    "# Convert 'date' to datetime and 'month' to a period\n",
    "payments_processed['date'] = pd.to_datetime(payments_processed['date'])\n",
    "payments_processed['month'] = payments_processed['date'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Outcome\n",
    "Binary. By the last observation date, denote 1 if the merchant has used Subscriptions; 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = payments_processed.groupby('merchant').agg(sub_min = ('subscription_volume', min))\n",
    "outcome['label'] = (outcome['sub_min'] > 0).astype(int)\n",
    "outcome = outcome.drop(columns=['sub_min']).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate payments by month for each merchant with sum, mean, max, and custom non-zero count\n",
    "monthly_subscription_stats = payments_processed.groupby(['merchant', 'month'])['subscription_volume'].\\\n",
    "    agg(\n",
    "        total_volume='sum',  # Total volume over the month\n",
    "        average_volume='mean',  # Average volume per day\n",
    "        peak_volume='max',  # Maximum volume in a single day\n",
    "        active_days=non_zero_count  # Number of days with non-zero subscription\n",
    "    )\n",
    "monthly_checkout_stats = payments_processed.groupby(['merchant', 'month'])['checkout_volume'].\\\n",
    "    agg(\n",
    "        total_volume='sum',  # Total volume over the month\n",
    "        average_volume='mean',  # Average volume per day\n",
    "        peak_volume='max',  # Maximum volume in a single day\n",
    "        active_days=non_zero_count  # Number of days with non-zero subscription\n",
    "    )\n",
    "monthly_payment_link_stats = payments_processed.groupby(['merchant', 'month'])['payment_link_volume'].\\\n",
    "    agg(\n",
    "        total_volume='sum',  # Total volume over the month\n",
    "        average_volume='mean',  # Average volume per day\n",
    "        peak_volume='max',  # Maximum volume in a single day\n",
    "        active_days=non_zero_count  # Number of days with non-zero subscription\n",
    "    )\n",
    "monthly_total_stats = payments_processed.groupby(['merchant', 'month'])['total_volume'].\\\n",
    "    agg(\n",
    "        total_volume='sum',  # Total volume over the month\n",
    "        average_volume='mean',  # Average volume per day\n",
    "        peak_volume='max',  # Maximum volume in a single day\n",
    "        active_days=non_zero_count  # Number of days with non-zero subscription\n",
    "    )\n",
    "\n",
    "# Merge the three stats into one dataframe\n",
    "monthly_stats= pd.merge(monthly_subscription_stats, monthly_checkout_stats, left_index=True, right_index=True, suffixes=('_sub', '_check'))\n",
    "monthly_stats = pd.merge(monthly_stats, monthly_payment_link_stats, left_index=True, right_index=True, suffixes=('', '_link'))\n",
    "monthly_stats = pd.merge(monthly_stats, monthly_total_stats, left_index=True, right_index=True, suffixes=('', '_total'))\n",
    "\n",
    "monthly_stats.reset_index(inplace=True)\n",
    "monthly_stats.columns = ['merchant', 'month', \n",
    "                         'sub_total', 'sub_avg', 'sub_peak', 'sub_active_days',\n",
    "                         'check_total', 'check_avg', 'check_peak', 'check_active_days',\n",
    "                         'link_total', 'link_avg', 'link_peak', 'link_active_days',\n",
    "                         'total_total', 'total_avg', 'total_peak', 'total_active_days']\n",
    "\n",
    "monthly_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends and Changes\n",
    "Monthly growth rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_stats.sort_values(by=['merchant', 'month'], inplace=True)\n",
    "for product in ['sub', 'check', 'link', 'total']:\n",
    "    monthly_stats[f'{product}_prev_total'] = monthly_stats.groupby('merchant')[f'{product}_total'].shift(1)\n",
    "    # initialize the first month growth rate to 0\n",
    "    monthly_stats[f'{product}_growth_rate'] = 0\n",
    "\n",
    "    # case when previous month total is not 0\n",
    "    mask = monthly_stats[f'{product}_prev_total'] != 0\n",
    "    monthly_stats.loc[mask, f'{product}_growth_rate'] = monthly_stats.loc[mask, f'{product}_total'] / monthly_stats.loc[mask, f'{product}_prev_total'] - 1\n",
    "\n",
    "    # case when previous month total is 0 and current month totol is 0\n",
    "    mask = (monthly_stats[f'{product}_prev_total'] == 0) & (monthly_stats[f'{product}_total'] == 0)\n",
    "    monthly_stats.loc[mask, f'{product}_growth_rate'] = 0\n",
    "\n",
    "    # case when previous month total is 0 and current month totol is not 0\n",
    "    mask = (monthly_stats[f'{product}_prev_total'] == 0) & (monthly_stats[f'{product}_total'] != 0)\n",
    "    monthly_stats.loc[mask, f'{product}_growth_rate'] = 1\n",
    "\n",
    "# Drop the columns for previous month's total volumes as they are no longer needed\n",
    "monthly_stats.drop(columns=[f'{product}_prev_total' for product in ['sub', 'check', 'link', 'total']], inplace=True)\n",
    "\n",
    "# Now monthly_stats includes the growth rate columns\n",
    "print(monthly_stats[['merchant', 'month',\n",
    "                     'sub_total', 'sub_growth_rate', \n",
    "                     'check_total', 'check_growth_rate', \n",
    "                     'link_total', 'link_growth_rate', \n",
    "                     'total_total', 'total_growth_rate']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_types = ['sub_total', 'check_total', 'link_total', 'total_total']\n",
    "merchant_month_variation = pd.DataFrame(index = monthly_stats['merchant'].unique())\n",
    "for volume_type in volume_types:\n",
    "    # Standard Deviation\n",
    "    std_col_name = f'{volume_type}_std'\n",
    "    mean_col_name = f'{volume_type}_mean'\n",
    "    cv_col_name = f'{volume_type}_cv'\n",
    "\n",
    "    merchant_grouped = monthly_stats.groupby('merchant')[volume_type]\n",
    "\n",
    "    merchant_month_variation[std_col_name] = merchant_grouped.std()\n",
    "    merchant_month_variation[mean_col_name] = merchant_grouped.mean()\n",
    "    merchant_month_variation[cv_col_name] = merchant_month_variation[std_col_name] / np.where(merchant_month_variation[mean_col_name] == 0, np.nan, merchant_month_variation[mean_col_name])\n",
    "\n",
    "merchant_month_variation.reset_index(inplace=True)\n",
    "# rename the index column to merchant\n",
    "merchant_month_variation.rename(columns={'index': 'merchant'}, inplace=True)  \n",
    "print(merchant_month_variation.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasted 2 months engagement and Frequency\n",
    "- Number of active days in the last 2 months\n",
    "- Frequecny of transactions in the last 2 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_last_2month = payments_processed[payments_processed['month'] >= '2042-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_days = payment_last_2month[payment_last_2month['total_volume'] > 0].groupby('merchant')['date'].nunique()\n",
    "payment_last_2month.sort_values(by=['merchant', 'date'], inplace=True)\n",
    "payment_last_2month['day_between'] = payment_last_2month.groupby('merchant')['date'].diff().dt.days\n",
    "avg_days_between = payment_last_2month.groupby('merchant')['day_between'].mean()\n",
    "\n",
    "merchant_activity_stats = pd.DataFrame({\n",
    "    'merchant': active_days.index,\n",
    "    'active_days': active_days,\n",
    "    'avg_days_between': avg_days_between\n",
    "}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data\n",
    "merchants + aggregate statistics + trends and changes + monthly variation + lasted 2 months engagement and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merchants_processed.columns)\n",
    "print(monthly_stats.columns)\n",
    "print(merchant_month_variation.columns)\n",
    "print(merchant_activity_stats.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot monthly_stats into a wide format\n",
    "monthly_stats_wide = monthly_stats.pivot(index='merchant', columns='month').reset_index()\n",
    "#print(monthly_stats_wide.head())\n",
    "# Flatten the MultiIndex columns and join with an underscore, ensuring all elements are strings\n",
    "monthly_stats_wide.columns = ['_'.join(map(str, col)).rstrip('_') for col in monthly_stats_wide.columns.values]\n",
    "monthly_stats_wide.fillna(0, inplace=True)\n",
    "\n",
    "# Now, monthly_stats_wide is in the wide format, with each merchant as a unique row and months as part of the column headers\n",
    "#print(monthly_stats_wide.head())\n",
    "\n",
    "# Ensure merchant column is the same type across all DataFrames for successful merge\n",
    "monthly_stats_wide['merchant'] = monthly_stats_wide['merchant'].astype(str)\n",
    "merchant_month_variation['merchant'] = merchant_month_variation['merchant'].astype(str)\n",
    "merchant_activity_stats['merchant'] = merchant_activity_stats['merchant'].astype(str)\n",
    "\n",
    "# Join the DataFrames on 'merchant'\n",
    "wide_data = monthly_stats_wide.merge(merchant_month_variation, on='merchant', how='outer')\n",
    "wide_data = wide_data.merge(merchant_activity_stats, on='merchant', how='outer')\n",
    "print(wide_data.shape)\n",
    "\n",
    "wide_data = wide_data.merge(merchants_processed, on = 'merchant', how = 'inner')\n",
    "wide_data = wide_data.merge(outcome, on = 'merchant', how = 'inner')\n",
    "# Now wide_data is a wide dataset where each row is a unique merchant\n",
    "print(wide_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out the columns with missing values\n",
    "missing_columns = wide_data.columns[wide_data.isnull().any()]\n",
    "print(missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the full wide dataset\n",
    "wide_data.to_csv('data/processed/wide_data.csv', index=False)\n",
    "# save the data after removing the columns containing subscription information, sub_{}\\\n",
    "wide_data.drop(columns=[col for col in wide_data.columns if col.startswith('sub_')], inplace=True)\n",
    "wide_data.to_csv('data/processed/wide_data_no_sub.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all column names\n",
    "print(wide_data.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
